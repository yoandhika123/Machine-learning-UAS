{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiIzGkJOG1v0VrVo/d6HJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoandhika123/Machine-learning-UAS/blob/main/Source_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOtRNh5hz8Pi",
        "outputId": "f13dddef-a8fd-4f0d-82af-fbe642a5a858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8.6611e-35])\n",
            "tensor([-2.6421e-13,  4.5688e-41,  8.6432e-35])\n",
            "tensor([[ 8.6432e-35,  0.0000e+00,  8.6555e-35],\n",
            "        [ 0.0000e+00, -1.1153e-28,  4.5688e-41]])\n",
            "tensor([[[-2.6421e-13,  4.5688e-41,  8.6610e-35],\n",
            "         [ 0.0000e+00,  4.4842e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 8.9683e-44,  0.0000e+00,  8.6449e-35],\n",
            "         [ 0.0000e+00,  2.0319e-43,  0.0000e+00]]])\n",
            "tensor([[0.1865, 0.8740, 0.7437],\n",
            "        [0.9086, 0.6505, 0.5087],\n",
            "        [0.9674, 0.3055, 0.5622],\n",
            "        [0.4618, 0.8323, 0.0076],\n",
            "        [0.3772, 0.1697, 0.8014]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([5, 3])\n",
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2])\n",
            "tensor([[0.6405, 0.0795, 0.7973],\n",
            "        [0.6917, 0.4587, 0.1125],\n",
            "        [0.7477, 0.1609, 0.8038],\n",
            "        [0.6400, 0.7366, 0.2677],\n",
            "        [0.4826, 0.6047, 0.4224]])\n",
            "tensor([0.6405, 0.6917, 0.7477, 0.6400, 0.4826])\n",
            "tensor([0.6917, 0.4587, 0.1125])\n",
            "tensor(0.4587)\n",
            "0.4587118625640869\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "# scalar, vector, matrix, tensor\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "x = torch.empty(3) # vector, 1D\n",
        "print(x)\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "print(x)\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "\n",
        "# check size\n",
        "print(x.size())\n",
        "\n",
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)\n",
        "\n",
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "\n",
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "\n",
        "# Operations\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "# substraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n",
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0]) # all rows, column 0\n",
        "print(x[1, :]) # row 1, all columns\n",
        "print(x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(x[1,1].item())\n",
        "\n",
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n",
        "# Numpy\n",
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    # z = z.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# The autograd package provides automatic differentiation\n",
        "# for all operations on Tensors\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
        "# It computes partial derivates while applying the chain rule\n",
        "\n",
        "# -------------\n",
        "# Model with non-scalar output:\n",
        "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward()\n",
        "# specify a gradient argument that is a tensor of matching shape.\n",
        "# needed for vector-Jacobian product\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "for _ in range(10):\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# -------------\n",
        "# Stop a tensor from tracking history:\n",
        "# For example during our training loop when we want to update our weights\n",
        "# then this update operation should not be part of the gradient computation\n",
        "# - x.requires_grad_(False)\n",
        "# - x.detach()\n",
        "# - wrap in 'with torch.no_grad():'\n",
        "\n",
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)\n",
        "\n",
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)\n",
        "\n",
        "# -------------\n",
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-h7Iacb0Xvn",
        "outputId": "699ec582-a7a2-4ea1-8d0a-24941d52a3f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.0791, -1.3634,  0.3830], requires_grad=True)\n",
            "tensor([0.9209, 0.6366, 2.3830], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f5c910d7940>\n",
            "tensor([ 2.5441,  1.2157, 17.0367], grad_fn=<MulBackward0>)\n",
            "tensor(6.9322, grad_fn=<MeanBackward0>)\n",
            "tensor([1.8418, 1.2732, 4.7661])\n",
            "tensor([ 2444.0928, -1770.0558, -2287.8340], grad_fn=<MulBackward0>)\n",
            "torch.Size([3])\n",
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7f5c910d7940>\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass...\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63HclfQc0bbL",
        "outputId": "d66e690d-abdd-49a4-c722-75a21899b4b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of3kW3nE0diR",
        "outputId": "f914fc17-bbd7-4ab2-b3ef-578864a5071b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sCki6FM0e-A",
        "outputId": "48f2b8d7-858f-4b7e-9611-fe5758edc924"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = 0.145\n",
            "epoch  1 : w =  0.2587515115737915  loss =  tensor(27.9825, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  1.476234793663025  loss =  tensor(0.8445, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  1.6792638301849365  loss =  tensor(0.1354, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  1.7189065217971802  loss =  tensor(0.1104, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  1.7320623397827148  loss =  tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  1.7407574653625488  loss =  tensor(0.0975, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  1.7485407590866089  loss =  tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  1.7559887170791626  loss =  tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  1.763199806213379  loss =  tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  1.7701951265335083  loss =  tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 9.539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "PjjAYFgj0gyB",
        "outputId": "8fb283cc-3a17-4f50-c1ca-8b64c5c5ea0e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4135.6226\n",
            "epoch: 20, loss = 2913.3486\n",
            "epoch: 30, loss = 2079.9290\n",
            "epoch: 40, loss = 1511.5350\n",
            "epoch: 50, loss = 1123.8101\n",
            "epoch: 60, loss = 859.2742\n",
            "epoch: 70, loss = 678.7520\n",
            "epoch: 80, loss = 555.5381\n",
            "epoch: 90, loss = 471.4241\n",
            "epoch: 100, loss = 413.9917\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URC438wS0iV7",
        "outputId": "75903e34-1097-44a3-8136-0a5ee01ee245"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5795\n",
            "epoch: 20, loss = 0.4773\n",
            "epoch: 30, loss = 0.4126\n",
            "epoch: 40, loss = 0.3679\n",
            "epoch: 50, loss = 0.3349\n",
            "epoch: 60, loss = 0.3094\n",
            "epoch: 70, loss = 0.2890\n",
            "epoch: 80, loss = 0.2723\n",
            "epoch: 90, loss = 0.2582\n",
            "epoch: 100, loss = 0.2461\n",
            "accuracy: 0.8947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # data loading\n",
        "        xy = np.loadtxt('wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "        self.x = torch.from_numpy(xy[:, 1:])\n",
        "        self.y = torch.from_numpy(xy[:, [0]])\n",
        "        self.n_samples = xy.shape[0]\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=0)\n",
        "\n",
        "# datater = iter(dataloader)\n",
        "# data = next(datater)\n",
        "# features, labels = data\n",
        "# print(features, labels)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        # forward backward, update\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n",
        "\n",
        "# fashion-mnist, cifar, coco\n",
        "torchvision.datasets.MNIST()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "I_Hm2Mf90kaJ",
        "outputId": "40dfe118-4be5-4642-98c0-24e927adbbe0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8146c266237a>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8146c266237a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# data loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wine.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: wine.csv not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('/content/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets\n",
        "\n",
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Ov2zeUXv0nsG",
        "outputId": "29563ec0-ae70-4ba6-e2b9-38e43de18ce8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Transform\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-11c96d04891e>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Without Transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mfirst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-11c96d04891e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/wine.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/wine.csv not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "# Cross entropy\n",
        "# Cross-entropy loss, or log loss, measures the performance of a classification model\n",
        "# whose output is a probability value between 0 and 1.\n",
        "# -> loss increases as the predicted probability diverges from the actual label\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
        "# nn.LogSoftmax + nn.NLLLoss\n",
        "# NLLLoss = negative log likelihood loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# loss(input, target)\n",
        "\n",
        "# target is of size nSamples = 1\n",
        "# each element has class label: 0, 1, or 2\n",
        "# Y (=target) contains class labels, not one-hot\n",
        "Y = torch.tensor([0])\n",
        "\n",
        "# input is of size nSamples x nClasses = 1 x 3\n",
        "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "# allows batch loss for multiple samples\n",
        "\n",
        "# target is of size nBatch = 3\n",
        "# each element has class label: 0, 1, or 2\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# input is of size nBatch x nClasses = 3 x 3\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9], # predict class 2\n",
        "    [1.2, 0.1, 0.3], # predict class 0\n",
        "    [0.3, 2.2, 0.2]]) # predict class 1\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
        "\n",
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yoV_e9r0oFq",
        "outputId": "e31f1730-502d-48d3-9e60-1715a07ca958"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "PyTorch Loss1: 0.4170\n",
            "PyTorch Loss2: 1.8406\n",
            "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n",
            "Batch Loss1:  0.2834\n",
            "Batch Loss2: 1.6418\n",
            "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YefFezWj0qJz",
        "outputId": "036379e0-8c16-4bf6-b4c3-22775146e971"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "jKVHxDGX0rtp",
        "outputId": "9d9f8cd0-54a3-4438-f687-5b32693a8e93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 99292631.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 19013607.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26530500.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12777014.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.3786\n",
            "Epoch [1/2], Step [200/600], Loss: 0.4849\n",
            "Epoch [1/2], Step [300/600], Loss: 0.3698\n",
            "Epoch [1/2], Step [400/600], Loss: 0.4342\n",
            "Epoch [1/2], Step [500/600], Loss: 0.2985\n",
            "Epoch [1/2], Step [600/600], Loss: 0.2019\n",
            "Epoch [2/2], Step [100/600], Loss: 0.0935\n",
            "Epoch [2/2], Step [200/600], Loss: 0.0586\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0653\n",
            "Epoch [2/2], Step [400/600], Loss: 0.1077\n",
            "Epoch [2/2], Step [500/600], Loss: 0.0944\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0784\n",
            "Accuracy of the network on the 10000 test images: 97.19 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "lky_tced0tZp",
        "outputId": "3e3e5de2-fe00-4296-91ae-e021d12cc149"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 71585162.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAACwCAYAAACviAzDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABP7ElEQVR4nO29eZQd1XXvv6vqjt237709qCd1t7rRgCQ0ICQQDcTGRg4QYkNgxTYPB3lY8SKWHIPeijF2TFacELGS94uH/DB+8cJgvxhjyzE4wTY8EJPBQkJCQhJCrakltdTzcPvOU9X5/cGPOnvvVl+6QdzWsD9r9Vrn9LldderUqXOrz97fvQ2llAJBEARBEIQyYc50BwRBEARBOL+Qlw9BEARBEMqKvHwIgiAIglBW5OVDEARBEISyIi8fgiAIgiCUFXn5EARBEAShrMjLhyAIgiAIZUVePgRBEARBKCvy8iEIgiAIQlmRlw9BEARBEMrKB/by8cADD0B7ezsEAgFYvXo1bNu27YM6lSAIgiAIZxHGB5Hb5ec//zncfvvt8IMf/ABWr14N3/nOd2DTpk3Q1dUF9fX1Jf/WcRzo7e2FqqoqMAzjdHdNEARBEIQPAKUUJBIJaG5uBtN8l70N9QFw2WWXqXXr1rl127ZVc3Oz2rhx47v+bU9PjwIA+ZEf+ZEf+ZEf+TkLf3p6et71u94Dp5l8Pg87duyAe+65x/2daZqwZs0a2LJly4TP53I5yOVybl39/xsxd911F/j9/tPdPUEQBEEQPgByuRx8+9vfhqqqqnf97Gl/+RgeHgbbtqGhoYH8vqGhAfbv3z/h8xs3boS///u/n/B7v98vLx+CIAiCcJYxFZeJGVe73HPPPTA+Pu7+9PT0zHSXBEEQBEH4ADntOx91dXVgWRYMDAyQ3w8MDEBjY+OEz8sOhyAIgiCcX5z2nQ+fzwcrV66EzZs3u79zHAc2b94MnZ2dp/t0giAIgiCcZZz2nQ8AgA0bNsDatWth1apVcNlll8F3vvMdSKVS8LnPfe59H3vZ8mtJvffkmFv2eOlnHZUjdQNdbpG9d9mGM+k51YRfTPjNKZnwZof+bIJNbEIdHcegR7JsfSDl0L44rLe4Zngmf9csqiI7P79G3SGlWF9R3TAs0pRNpUk9XKE/O9i/Z9L+LL1wLqkHAhWsN/o8A719pM0X8Lllf3WYtJkFm9TtfN4tD2VipC2fzrrlea0XkrZw0yxSz+bG3XKlJ0DawPTBZOTR+W2b9U3ROWk7uu6wz3q9evLz4/C5Vsoei/92Qn9YHfcdlwEACoWCWz5+9Nik5wMAeOg/Mm6Zq/OwXG+CdM+idQO182tUJZ5Zy6QLh2niZZGPFZrrrD8OemZMdn7+5BnKPGUZgD7DasLqQ+t4TCw+HmCRGjkKGw88XqZFn2Hw4HPQuez10vrHVh+AyWhZfYVbbptzEWnLZpOk/uIL/+WW86ytYZbeQR8a6Cdtx451kfrAkDbjx8ZGSVs4qHfcL2htI22ZLF23Fi/R61FTMw0XMZ5IuOUTg3THv//ksFseHhojbfV1daQeCgXdcjBA15D6+lq37NgZ0jY2Quv/+dPfuGWfQ49TQOuf5af3uVCkz3AA9SEajZK2m2/8FLxfPpCXj0996lMwNDQE9957L/T398PFF18MTz311AQnVEEQBEEQzj8+kJcPAID169fD+vXrP6jDC4IgCIJwljLjahdBEARBEM4vPrCdjw+KXqaimT271S031EdIW5H5fDiGtvE5wOyayOeDm8Qtiw6T1zv5sFFbL/e/0G0OdzGxqc9FYlTbCp08temFq6vdssdHbXpFduB0RvstjIxSm6PHp+21tfXUh4H7h1ATMW0rIjui30/709tzktQP7NkJU2Gwn/4dH6+KipBbtlljtqDHuaaykrRZmQKpFw1t7z8xROfWzh2vueXeo72krXH+PFJ/Y8frbjnAfHRCUT0vL7yQ+o40Nze7Ze5TMdHdQP+ikl0Xts/GYjHSVsq+z8+JfTWKxeKkbQBvO5JPxnQUbKapn8WJrlDYn4j/r2Sxz07u84GrBpu/phFkdfx8M58LfJwJjhx6LLmflpcttRY5LD2HbapJWlgHWJ2PD+0D/zu2NqnJWgCMCX+rcZyp+b8BALSgtXp2UxNps3NZUvdf/adu+cXfP0XaBgeOu+WxkQRpMxS9l5GwPk8iSb8PxhPal8RgDoNz51GfM+zLNjJC11ETrZUBHz1OM/IPCVXSvqVSKVJPpPVYnuwbJG0jI9qnbMH8dtLW1ES/9/xB3YfMOPXjcBzdV1Xkzy+9z/mc/tvx8TicbmTnQxAEQRCEsiIvH4IgCIIglJWzzuzi89Ct4Excb4fv7tlO2prn0K09M6C3p1SRbjEFLV33euiwJFJU6oUDqPHt3WIRbVvbdJs6V8DbXHTLOBWjMrChbi1Zu2LlMtLWdsXlbvmNrh2k7fARKmvc/eZbbvngwSOkbdHiJW555aWraF9zdIsyl9VbcFxe5/drGWwoFCJt4SoqJ7PQlvbkm/YA46MjpK5MOl6ZrN6mbWxqIW01SFUVqqLmiWKBbtPm0no+Heun92DPYS3TS2eZeSJAx2D/W4fcslWkn/WH9Gd9Pvp3OPAel6uaTDqJJZCZDDXFcRMJhs9RCx2Hy1dxm4c9ByXlmew4uO1g1+Tyy7c/e+oyP85EeTr/3wmbXdjYYckuk4MbQE1EpJ1J8JWyJ20z0BpiMvks3+LO5fQ2ts9Hx9Xr1+sUNw8rh8vcJzet0HGd3FzD2yeIe09TcnFla/lqKMgOyswe0fnz3XJdlK4hP/vZT9zy4YOvk7Zkij7fl6y6zC0HmdnjGFpjh5kppTpKc5P0obUhnabnWLpMy4b5fY9G9NrY3EzVnokE/V450Tvklo+wdTyT0GM3r6OdtPmC9Dmtr9fj1T1Opcj4+baZqZ+7E2CTbCFPv8tOB7LzIQiCIAhCWZGXD0EQBEEQyoq8fAiCIAiCUFbOOp8P06Y20HRS29/e2rWbtCXGqQ2/draWT1WGo6QtGEXSTWaOPNTdTer/+ctf6fNnaBheA4VY9njpu11buz5/MkGlZUkkrQUAWNyipa9+Zvs/eUT358n/fJy0bX72OVLPI1+NQID6P1SAtrOmk/Q6fGHqu4GlZmE2dgsWaPnoKLNjgknDok+0058am/kXzJpFQxrXNmhfiWh1LWnD8mMecjqnqD9G35i29SaDUdLWfPk1bnllK7XXzmmh/Vm2aLlbVgVqS1WGrtfX079radH+KhOkrGwMsA9IMknHGfs0VFVRe3WpcOvcjwP3gfsJlAq3Pp1w5hzqOzK5fwr341DcdwPVuTwUy2stFu7eAB5eHec2YH4uqOzwlAz4Ohzmq2FTWWV/75tumammoa71Yn1ID2tU/PmxSrRNfn84lkcfx8vkonnkG8DV1dO5z61Neu5bBp1L2Txdf97cpyX5AT9dixrq9LO4dNElpK22ln52aExLVrkMNp3U92Rfz3HSxlM2YGzmy2caej5ZHjoeKy/T60IoTO8l97mortZrZVN9NWnLIZnw4AkahmCQpYwwkfzZY9H77kXzIJ1l65SHhZ/AxzQnb3uvyM6HIAiCIAhlRV4+BEEQBEEoK/LyIQiCIAhCWTnrfD6KzM4bbZjtlldd+RHS5g/Qd6sAshVWRGk48dmztTZ6uL+HtPlZ7Io/+si1bjmbp74bYGo7WrQ6Spo+dMUfueW3du8jbTzteBilVz4Up4bWipy2VVoeGlo3zLTaH13Y7pY7mmaTtvFKbVccCdWQNk8N9U0wDe1H0dRIj7MKaemPHKLXpYo8PHWp6B6aeQsWk3o1y4jsoBgUOW6HtlHqeaZPLxi0P33xmFtO1dC4MO2d17nl1bOo70prBbWztqBwzDy0tipOrpHHPg08XDmOZQIAMDik7dcTQrEjeCwR7kuC4cexeDp1BO+f1+udtO3dfAwmO2fJOB8mj03Bli8Dxy9hKe2RT4zBYpKYLLIFvn2mRa/LdrTt3bC4P4h+RgweHMOgMVyKBR1/YYyleq+cpedSRYjOuwmhzsl6yGOtoJQRZun7gX03JrhxlLiXtj215xkAoBqtN8U89x+inx0e1D5NR7r/QNr8AT2fV11K0xzURKn/18l+vT4OjgyRtrf26BghRZYWIpOm9yuV1HF1PF76jBw8cNQtNzRQX41UQq/VRZvGTuKxegI+ff/mddDYRdk4irPEfHs8XurL0tHa7pbHhqkvTQb59k2IksP8OrDPWal14b0iOx+CIAiCIJQVefkQBEEQBKGsnHVmF4tJhxy0Jdh18BBpO969n9TbUDjxpZddSdqamvV23Yneo6Ttqd/9N6kfPay3TFvb59BztOut+9cPHSRtR/Z1ueWBfiqtTaboNl9jW5tbjtTS8MJDJ7RpY8srdEsyGqAhhBtQ9sj5ixaRtrGobvOw7JRpJicD1O7zUYlWsajlzgEWNlnZXA45tW3acA3dPrWZKSOV1luYPrZlaqBQ44UiC1nOtigLaAu+h5loxnL6mt/cT+XWNXPp9iqY+roU2xon4eiZ2YeaaFiYbRbevIDCr4+PxUhbEe1blwqDDkBNJNMxl/AQ6pjpSC4nHBebXVgbzVRr8kZaRaYF/tlSGW+5nBbfIwPoXM9ltDQ7lR4nbeHqdrfs9dLn0PDQueXz6O34eJyGwE4OaxNsBZN/Kw81qeG4ANyyYuBswRNMVvSz+PblmZkO7/IbJvvK4OHeS5BM6HXCw+SzlRU0xP3H1qxxy8dPdJC2wUEdFn1kmEpkd+3ZS+p5dPuGh2Okra1Zy/Wr2DoeCVBz15tv6XPuOUC/Z4pFvRaFa6gZPBXX8yUeo2vReJLWAz59vxoj1OyN5c8+g84BH+trpE6f82jfCdJ27KAO6+/10TEvlMhSbZwiv/L7RXY+BEEQBEEoK/LyIQiCIAhCWZGXD0EQBEEQyspZ5/NhOlSTFQ5qe39jLZWLdu2hqY97juiU8g2z20lbuk3b2Bpqqd2uuSFK6of3a5tfnKV+T0W1rdfjUHuxg+pj43HSlmEuFoGUtiO2LaAy0+5u7UsyyM6fYybhTVt0mOI3xuhJllyj/UrsCuo34TVo/yxkjbcU86PAkj4PPY7iKcGn+L6bYRLmIPN/MFDaeq+f2p1xavqKAPXx8LEp70U2bBvo+OSyWu7nMNlrzqGfzWS1hM2n6E1IIV+SQpHK7UIVer74uCGeheiuQGPrt+g57KLun2OXts9inwcuoaOSy6kfh/uDlPIPmQAJgc99CPT9MXiIZ4PLaY3JmsAk8lnml8S7ii+bjUHQo/92LEGlmykULtsXomtIOtZLz5FDPktFuqYVhvXz7cxqpV2LMF8jJDe2FLXZk/DzPPw9PQrxCeG3Dg+7adLnyZjG/6+/f+V5t/yRD19H2jwGPW4/CoueHKfPmqX0emgoKlPuOUFDFhw/qcMmFAt0DKortN/JnEYqs59dQX1SQqDHtpuFN4/O0j55NvOBKRT1+Dgsb8dwf4zUnYz2AyqEqUR22YJlbrm9jfrAbN7yAqkfHdLXbDEfvCLyYQpYzOeDpYUwPLrvPBT86UB2PgRBEARBKCvy8iEIgiAIQlk568wutmLbPyjKYH0jlSd9dA2NeGqgrVDFtptH+gfccjY9QNoCHrot2lCts4bmC3QbfWxIb8VGwzS76MIF893y4MgYaTNZRL23dmtzye7tr5G2Rct1BMQFC+aStmP7aITRw2m9LXnwD6+Qtl5Dj8eiJUtJm8rR/nlA92+MyVWjaIsymadTqqKSyoSdKSq2kimWtdWix/V5dB9MFmURqV5BsT1kni3XY+vr8iWoqam5Tbe1NlKTXoFJMLGM0J+n45NDEU6LzFwTwBE8mckhx8wnCo1BkKdCxdfJttiLzFRZSmo7HbPLe5XscnBkRQO4NNuDPldaamuSaKiTm4FMlr1TcRmq0u12nm5NGx49D3wV1AQyNrjNLScH6HgU0/S+G7Y2kwWBmiqdlJbhJ4apVDJc1U4/q/Rc4xJvA0VVtTyTS4/frk+eWRhHJeYmPQVTj3AaQ6an0VEqL66saCf1PW/sccs9x9l67Nf3pKmJPpeOTdcJE41JfR1di+Ijem0c7KfnUECz2tbV6L9dfAGNPjqa1iaSYixG+5PX43zixCBpy8eoW0ATis6ajdH1rwo974aXmZltepwiMu9n0vR+Wch8bbDvUi8zR9poTuTfxZT7XpCdD0EQBEEQyoq8fAiCIAiCUFam/fLx0ksvwcc//nFobm4GwzDgiSeeIO1KKbj33nuhqakJgsEgrFmzBg4ePHjqgwmCIAiCcN4xbZ+PVCoFy5cvh89//vNw8803T2j/53/+Z/je974HP/7xj6GjowO++c1vwrXXXgv79u2DQCBwiiNOD5u9LsUz2jZ2sp/KrE4cp2Fws0h6ZnmpP4bfWOiWx0boy9JgPw3hm0ppeevQMLXNjQxpe6TNspke79HHKTKb68keatsdH9R233yW+pXsSOnjXLr0EtJ27V98htR7B4665WdeeYm0vblN19MjVD7W3k5tqW2zkJ9Lhl7zobe0PdAfpdLAygrqmzDVML1c9pVOUemZz6clqpaiNnwfks96WdjmfDpF6kZRZ5YMDlK7bzOS2loheh29g1Ti7EEh1P1F6vORRrJhh4Xy7u/Xtm+LOcTkmQ0WUIhlk5nafcgfxGL+DrkCk0Yjm34pnw8Ob8MZcXl23On4fHiIbJj7IuCMt1wDysOrTx5CnbQxya7FDquQH4XBQlc7EHbLoTo6rpmhzW65kKRzyaPo2mcS6TrLnAt6TsZH6RoWbVlC6j6UjVo5dDm30PjwtBQc/LwV2bplUCcq2tdp+AKkMtrnY2DoAGmrpMpWKOT1+hcM0v6Mx7SvRl0dzbAd8NLn1FL6+U/GqVw+ldLXPOSw7OQsC3FrvR7n5bOpr8/OvVraGgzQC7EHke/ICE2pUcMzxaIMuKkYXafwc3pygMq2uc9SMqXHK85kyjg7eTFPs+qCyWX3+rjTSF48Zab98nH99dfD9ddff8o2pRR85zvfgb/927+FG2+8EQAAfvKTn0BDQwM88cQT8OlPf/r99VYQBEEQhLOe0+rz0d3dDf39/bAGJQWKRCKwevVq2LJlyyn/JpfLQTweJz+CIAiCIJy7nNaXj3e2kBsaaETOhoYGsr2M2bhxI0QiEfentbX1lJ8TBEEQBOHcYMbjfNxzzz2wYcMGtx6Px0u+gBgsdHXAh1KJe6k22/DS8MezZ2kddWUFtamFK/XLkZOn9r7Vly8m9euv/yO3PDRMbf89x7X9z2NR++P4uLYrvvgSjd0xdJL2HUez9VrUh8BCprqjB6h/SqWPGueWrVjglvMWva7du7rc8uAQ9WvpmENjpiyo06HYHaCpxAeK2pZZF5pF2kJeek5DUd+AyQgGqY3cZiGoY0hP76uhc6IS+2fw8OEspT2guBu1LGZBC/LPSCRoGOehUeojc+yI9jeqDteStoM9ui1TpOPhRSnSTeZ/kWah2IlzQp6Ohx/5fMxtp+GXG2bR+AYNDfreelnMFu67UQrsAzJ1D4+JeL3aLj/BVwT78zCfD8VDhqOqyRw5LGTP5nEsuB8S9jMhIcoBSMyLUBUNoZ4J6hTtsfEY7ZvF8icYyF+GPRMFNK7ZDP2nbTR2hNRn1+qw4LYdJG2mM7lvD7/P5F7ycS0Rbn46vj2jo9qv7fCR12l/HLqmvNWlYxL94Q/bSZvH0n44x0/SOEeDfXS8UsjP41gPXStNNLeyUepjFm6ga3ddpX6+5l28gLRdjeIu5Yt0nN94Y5dbbm2h60K4mv6TvvugHp9QFfU16uvX3w9DKWodONlLfUlOntD+Rhnmf5bL6+v0OPzesXuL/YScMzy8emPj2w/fwAB1thoYGHDbOH6/H8LhMPkRBEEQBOHc5bS+fHR0dEBjYyNs3qy9vuPxOGzduhU6OztP56kEQRAEQThLmbbZJZlMwqFDWv7V3d0Nu3btgpqaGmhra4M777wT/vEf/xHmz5/vSm2bm5vhpptuOj09ZlKvykq9bb26cxFpG19ATQDFvN7Gzmfo1pXfr7dFGxupXMowqCw3gORULa106+zCBRe65WNH6A7Qyy/r7cOhfmoSKjKzAs4GW2RbnaGA3hLMsWyDew++Rer+iN52W7ViBWmz8vocqRjd9pzFQlAfHdBbgstW0G39lllz9Pmq6A6XMqhJZKrCPC7rrGRSV9vWMli+xY5fqRXTiHFZbrqAQkezzuVTekzGPdRcks9Qk0hfL5LMBllfg/oeOOz8RQuHiacdcLKs78hc4PVTCXFNVMv/kkUqG2xgZoYECgUfjlDTAd6On0549QlpZJ2pa/P8AZTZ18vmC3rei2xLu8DMZNjswkPVU6ktD6fOQrFjeS8Lo69Aj10+Q59h29HrRMGgckzDoPfERCY9k5lVTb+eP6EgXV+Uokt2FmVbNljGWRNNaJNLj0vWeQh1VFfcJDP1/18PHTzqljMsnUSKmRLCYX0t8+Y2k7aRES27f/11ZpJh97Yuqu9J6xz6fTDYq03muQxNJ3FBMzX9z67Wa35liO7O1zRpua9j0/vsTaJQ+eyafbNoJl1VoeW8vYPUzHuiT8trjzLLQjJLXQjaL9BrsBWk5pueQ3qdGu2N0fMzib4HmaznzpkDp5tpv3xs374dPvIRnTPlHX+NtWvXwiOPPAJf/epXIZVKwRe/+EWIxWJw1VVXwVNPPXVaYnwIgiAIgnD2M+2Xj6uvvrrkf0SGYcC3vvUt+Na3vvW+OiYIgiAIwrmJ5HYRBEEQBKGszLjUdvpQO28eha5O56jkaGSIpjBWtvbr4G4CYzFks/cy2RVT4MTGte2u7yS18e3arsMGv75jN2nrG9A24jxT3jnsVjiAbe/0wzFkn3Qy1FfEStHxeeqp59zynu17SVtrjbYNXjaH2lWXr5hH6qkWbTuNZ6k9sjCs7eC1XmrrtoPMfjxFZR4PNuf3URlhqAr54TA7bw7JZ4Ms5LQq0hufQSm440yWu/eoljV21NI5UMkUqTiNteOh11xVqe2uJvPtARQKHliTwea6B6VF52nhqxq0jC+VYKGZuQ0f+WMUmKzcQbuaivltTHTrKOETwkNHl6AqpO+ll/l8YIVfvsDmOhsfx8DSX+abQPwW6PkN5kdhonDnuRSd66m4nhNjo4dJWwFJoyvrqM+Al5md/eg58QeoL0IgEnXLwQrqk2NaTA1o6c86QMfOQJp8Lifmu9eldrNNHHZ7go/H1P9/VUWUhsFDxzzop31vaNF+FNkk9a860KUDVuaY714bS3ffMUf7VTQ2U/+ZY8e0H5uvQK9/1YJ22nel+xAbi5G2AvJrq6uj92t2h/YBHGOpHU6M0GdvdETPtUyOprDIFbWfS28/DcuQZWvKlcu1b1/HfDoPuyJ6/mzue5W0GQ7zpwzqNfcjHzr9ghHZ+RAEQRAEoazIy4cgCIIgCGVFXj4EQRAEQSgrZ53Ph8HCYzvIKJxmeudcjqZh9yLfAH8FvXSPX+vKlU3ts2+ilMkAAP/3qW1uueutE6QNUDruQIClc0e2ueIE5wcWOhrZs3n4ZWVr++ME2y07junR/TlynIYE9yAbcfUlC0lb5xWXkPrrIzpE+Ik+qjP3o5ToFtPr+01qr+W2+Mk4eZKmjTYNer+qq7WPg8NSkmOPHZOFELZYLA0b9d1fQ2OUpAvan6eQp9cRqKD6eZ9Hz5lKi/qn2Oiax3MJ0mai+RxwqJ9Evkj7juNaOMxpaAyF+beYDTgboM9BEIV0t4vUv8lGcWPUhHvFYzyoyZomhEIvhdevx85iab19Pt1XD4vZ4uM+J8gpxWQxC3B4/nyB2tqBzR8cQnw4RdOOF4q6P42zl9L+oJgKFk+J4KFzwmdp3wCPh8YRspD/g8Ge50KeXrOJ5hrPbl8o4hg2PDw2vWbiNlUi6rbJws2b07jPl6xc4pZbGqn/RaCCxlaqRn4vSxbT9BaZlH4WAwHqK9LeSp/hcKVeg3M5ei/z8Zg+H7uOSJCuNyMoLlM2Rf38rDHtq1ERWELaZrXNd8tmJkbaesdouPdUSj+n3gr63dHaon2EUuwZ2b6TxnZqb9d+L0sW0/gco4N6fTb5rSuy71b0nKQSNA6Kz09Dxb8XZOdDEARBEISyIi8fgiAIgiCUlbPO7ML1iB4kzasOUpmTk2fbY2iLu6KKyfbQtnnvcbql/dIL+0j9jV3aBFFfT7cPw2G99ZpM0pDl8aTexuLZMg0mTTSQuYBvfxtIAsnljybQ4yhAob1NukVpI7nbINBrPsZC+M4CvQ3Y6Kfj3JPXpoSAQ49TyUJiTzUH5tAAlU0f66ZZd5ctW+aW2zsuoH+MzAoO30p0qPkkX9D9Nb01pA1yev6Mx2h/2pvplvulTVrSxlSwUBnWW97VFs0wi3fDgzbLMMujxqObXWDy6wKSAkbY/xR+ZgYqIslqgWVbVVjiTU8PdolQ2hMyocLUs2CaaB76fNTk6fHoeadYSHuT9ceDTIw8i2ve0c+elyeqNWlfcZbdhRdR86MfmURMtv2dR6awXI6adrh5dKrZYLkC1hegS7aFQqoXCjwUPBo7ZrY0DPZc4nDvbD9eIQkm74/HM/WvkCoU6rzI1vGhMfp8pVJaahqpovL9llYtnz1xgprED3YdIPUgMoV5vNSUUQF6rlWxdSsbp2t3JcqyzcPxp7P6Xg8O0vAO0XptBvKwJypSTc1tY+j7anScSryjSktkWZQGiETpcSoqdP/SLGx8AD1fHounvqBzMonMQEeP0fW3uo6GYngvyM6HIAiCIAhlRV4+BEEQBEEoK/LyIQiCIAhCWTnrfD5MJrWtr9FheNvnziVtsbF+UrdxCF2D2o9TGW3fevJXm0jb66/TMMqmpe2IBrOPDg5rSVYuS8+BlYLcJj3Rd0PDbXGOMbk93bCpRRCnmPazk6Tj2q5aEaXpnYOzOkh9dEjLdNvnLSNt9rC2c1bX0uP4TGpnVUziNxnV1dTO+9prr5F6d3e3W77mmmtI28KFun+VFg+vTscnX9T2Wk+I+hsEvDrs9XDvm6Stf5xKii+q09c9OEzl102ztd33wwuoFM+HZKZ5i94fLwv77UO3Peuh4xg39XVVMplnvJemfj9y+JBbTqepDBeneucSZtND7yX2W+Dz2ZlGeHUfssUHAtQ/xbH1OTweZqNmcnXcH4ud3+vVY4Llu29/lh7HRM8M7w/+W5zOHgBAIdm/xeYdl5hjvwruN2Gi/hTy9Fl3mHTcQa4T3FfDh328DOpj4TAfB0A+ILyvWNHs4eM6DZ+P0Zj2P4jMoWG/4yMjpB4rxNxyLsuk0YhDB/aTesBL+1Mw9H3PMJnykgb9XFYG6NjlfbRegcLje5nfTSah1/nuPnodo7aWwQb8dOwOnqR+dftP6PACceYzVF3QYSSyOSa3Zut6EUlkh4fos59KYrkxC0PAnKHyaMrgUPQAACtWwvtGdj4EQRAEQSgr8vIhCIIgCEJZOevMLgB0OyqZ0pKoEyeoPKlYpDKjoF9H0fN5aXbII4d0psBnn91C2lIZur2Ko/z1DVDTDt7Cra2m2SoBtJkjkaKRLj0swh7e8raYdjMcjeojJulx8jkmda2o1Occp5+ta9Cmgqs+ch1pm7uCRepLaimcP0j7cxHa/laKbmkfPky3IRXQyKWTwaWItk23jQ8d0qaDVIJeV88ybSL68Ic/TNqiEdo/rw9tsbOogpGKqD7H0BHStu/IUVLHEjYjR00yRZSB15Oj5olQpd7WL7BxHStQs11lSN/LsJeaVqqROdJkGTrr5tDokeEqXe/upibFrgN6m7ipicrIuZnBQXZEk6eJnsZ2vN+vx8A06XUViXyUnmOCqRL1gZsO8HziZg6LSdBpG7sOZArzelgH/LpetLkgkoJlwX4/vWZsdsmadMzTaTonsITXYvfAwgPEpdBcR43MLlxCbOKvCT7oJbLhchLIzDs+Sp+RpkaaVTuV0OaB8XEqe22o0+vqgnkXkrZMlkYxrWqod8tDI/ScRw5r+egQkvYCAFhL6HHDlfo6C2wtOnhMr2kDcXq/dh/4rVu+9sMsM2x1lFQLKGxEbJj2NYeiLQf9laTNZPfAQhJiH5u/J4/rddNmpjevj5lV0TzI5krP5/eC7HwIgiAIglBW5OVDEARBEISyIi8fgiAIgiCUlbPP54NJxmxb2/gKNrW3xRPUvyCR0Das5Di99B88+IhbPtp9jLSFq2jYbWyvTSRipK1IsmdSO1k4ov1M0hkqcZwAMq1yCV0ASRMdPx2PuhoaatdEkr9khvrL5JH91vax0N5eagffs79Ln2NWlPYVhV/OpWl/ijbtz1TDShfY2IVC1G8hmdQ22pFh6lfy4vPPueVxJolduoTKsdMoa6lTST9bwPJDZjvt6acyuepKbYdtjdC+jhT1+LzCsv4WY9pPqZZJZA/1UXnbJRfoMPIdKOsnAEA8ocfj6AE6f0NsTsxu074+lZXUfpxA/jM1zCY9xGR7SfTZcJj6UFWwrL+lMNHYOnT6kDpPPuvzM/8dJLPk4cwdkpKAhWW3+DJYao7qNi97RrBvlmOzUOesP/iZnhAKPq/nJF9DuIQYZwHmzxb2P8MS6rc/zCXvbOARNLz65OP6bmRReonBPjqXlEPvwdCI9tcbGaLPmkIpG6IRml1V2dTvr61epzNYwOS9ex19/7Y++zJp83uZXL4u6pZzLHt6L7qWvEGfYQ9aV2siNC3FCeafMjik+15gctrmWn0dkRB9to6w76uTPXqNmYMy3AIAKKXnC3PtgWyO+hNhiXWRp0w+DcjOhyAIgiAIZUVePgRBEARBKCvy8iEIgiAIQlk563w+TEXDbldH2t3y/HlR0jYep/Yu7Jvw+g6aenloUNuvHWbzXbBgPqnjeAd73qRxPnwerbFOsPgT2F7qZXEaCizsdxCFdeb+Dol4zC3Pm0d9GD7zmdtJ/dlnN7vlZ/7vs7SvKDZEJbOfhyvpOZdcdJFbrqhgsRiQDTadpLbu4z10DKYK9yG49NJLSb2vT8dlOXGcpnuOj+lz9pw8SdqOH6P3PdCkQyw3eaKkLYJ08Caz4XuZf8YIslH7mf36ue5tunKSxp4pIv18XYr6LI2doLbc4YU6jXVI0c8OZPU1nxyg6clDBjXuRpFPis9H+5pH8QROnKDjWsizMNfIDOxlYa1xePGqMPWZmoh+Lm2b+RAg/wx+Du6rgeNc+FjMAhzbg/spcF+SPLrOIovpAAYOP89jXpDe0DaWVqBYVKhMn31b6XN62DwD5vOhUHp3k61bXgvHNmH+IGzlN3DaCuY7YpBrYaHXp+Hz0Vyr43NEq+j6UuGnfgw2aq7y0hD3jXXaz2Ogl6awrwnRdaMS9V2xeE1VKGR6IED70z9C437Y6OZaDl0Lmpq0D1VNHf1+WuzoZ3b2LPocxEepr1oU+V8li9T/ommWjrlTX0uP08NCn/tNPZYehz4Hi+YtcMsDLC7W4e4+Usc+TU5xcp+g94rsfAiCIAiCUFam9fKxceNGuPTSS6Gqqgrq6+vhpptugq6uLvKZbDYL69atg9raWgiFQnDLLbfAwMDAJEcUBEEQBOF8Y1pmlxdffBHWrVsHl156KRSLRfj6178Of/zHfwz79u1zJXt33XUX/OY3v4FNmzZBJBKB9evXw8033wyvvPLK6emxSaWK+WLMLQ8M0raBQRoS+8Qxva300A//k7QdOnDULVdV0q27wUFqWonHsSmBSpBwGHC+hYzlda0tVPbV09ND6l4k580zCVTR1vVVq2iG2cZZVM5VjUwkizqoGeqSC/WW4Ojxo6Rtn4duLfoq9XZr0BslbTi7qOVl77MW2+KGqUm2AgGaYTbCZGom2n72svDzx3u0xNpmJpB8gsrkFrS1ueXKSnrOVJ82e3htvg1aT+pVyGzlsGseHtLzJx6jZigsb+vK0rZgJZXIzjqpj5M5RrPsZkAfxxekf5ex6Vb5saM6pHowSLdlo1H9t/aEDMn03prIJJJi5rYkkv4uWV7a7ILnOo/SbqFw69zMwhSzJCw5z1yL5bVcxl106L01TJTagPXVQBJV5dC5TOSIEzLuwqSY/F9AZO4bH6MmtNktNNu0aeo5q1jGWwvJZw0mrfWyDKZen65zOa9p6HHnsn/FbVYlrDCdy1a55VAlNbOMJ1lYdL+u80y6DjINHovTNX7ZRYtJHZvbjjMTrIPmQcDL1iVmZcgV9C8CLNxDEMlplU1DKHhw1mF6SKhh5vSFaH02mWQ3iszQY6PUXHJBC02DsHS+niNtbTRs/fIFWq5//Agdj8NHqPlm0QL9/bBsIQ03fzqY1svHU089ReqPPPII1NfXw44dO+BDH/oQjI+Pw0MPPQSPPvoofPSjHwUAgIcffhgWLVoEr776Klx++eWnr+eCIAiCIJyVvC+fj3cS/tTUvP2fzY4dO6BQKMCaNWvczyxcuBDa2tpgy5YtpzxGLpeDeDxOfgRBEARBOHd5zy8fjuPAnXfeCVdeeSUsWfJ2BtT+/n7w+XwQRVlXAQAaGhqgv7//FEd5248kEom4P62traf8nCAIgiAI5wbvWWq7bt062Lt3L7z88svv/uES3HPPPbBhwwa3Ho/H3+UFhNrC/D5to66rjZK2UIjas0NBLdG6/roYaVtx8Qq37LGovfhnj/2C1NNpbZtvrG8kbam09ingoZHTGd1WYOnSFYsrnU1r22GuSCViH7pipVv+0pc+T9pmVdeR+qpLluhz5pmcF8kRLWZP9zBZozK1Td/rob4RBrJv53JcjkltqVMLrj5Riuz303uJJX6z6qnNs4Bs7/k8Hdc0PQzUohdlj0k/mylou3OY+UYMjVO7axb5fOQa2Zyo0ffEqqJttkf/XdpH/xewK+g8HEto+7+PSSejKM12RYCGTC/kqT9GsaiPy9OwHz2obeg2k4BWz6KhrCN47DwsPP80ojH7kZzU46f2feyrwVO9czktDtPOfSwKBT0GDvufy2T+IV5kwzcU+yzyAnGYT1cGPadcguoxuERVf3aE+aYlhve75SNHj5K2aOhPSP2CuTpNu+NQPwoT9Dm4Lw32hXgbJCFmUlLT0m08hDtXIjP3GcLieUvdcjpL14mf/eJHpL5r1+tuef7cOaRtdFiHM29tmU3aopFZpJ5BIcyrquj8bWnS/g+9h6m/QzJGJfF4HSuy+x5P6nU9kaFjF0L+g5ksfZ64X9uSC7WvxjvWhHdIoXQSsWEqgWeRD6AZhYJvnkWlvyHkR9ZQT/3WuHQc9+/SS5aTtgPH6fr3XnhPLx/r16+HJ598El566SVoadFOMo2NjZDP5yEWi5Hdj4GBAWhkC/I7+P3+CV8sgiAIgiCcu0zL7KKUgvXr18Pjjz8Ozz33HHR0UM/rlStXgtfrhc2bdWCrrq4uOH78OHR2dvLDCYIgCIJwHjKtnY9169bBo48+Cr/+9a+hqqrK9eOIRCIQDAYhEonAF77wBdiwYQPU1NRAOByGL3/5y9DZ2XnalC4O28aPj+vtqJ4TVOaUzdLod3gv+MqraH+wvPZ//+Bh0jYyRI+zEEmQvrx+HWnbvnOHW/75JirnTaf1FqBt0y1km0XQdJCEraYqStr+x23/wy3X8u25NJWSYjliRQXd5sMS3gLbJm6sp+abyiq9pZtk5ygi00YwyCWONFLgVA0vXO7HzTA8uyamqVGbYTIsquEw0HHG2892hvYVm8YaGukWZY4dd+8b+r5neppIm9WItlObaVtNo95SHjbp2MXiNPMnpGNu0eeh/zcYKBphnu2FcxOfjfSQhknHNYRMNoPMT+tg/CipR1CWZh/L8BqcRlZbC235G8z8iCNzMkU1MMsTGOi6eLRPnx+ZUtgcVdbkc0lNMLug8WLnzyAJaLFA5xmw5xuQLHYgT9etg4d07CSLXXQux54npbfyvSxzbdCL5bO0sxOy0yJTAlPskrXIZnOL10s93bERbTYcS9I5OTBEzRwOikbtY2ZeG0nHufQ4Wk2f0wUNei2wmKmpa99bbtnPTHjA1spcVt+jLDNfD8X0vfUH6Dl8QX0d8QS9z6tXryb1WpR1t1hkplIcdTdFZcm7d+4k9UZkHq0K0uiwCt0vA7gcnM71ARRFOpPh6/j7Z1ovHw8++CAAAFx99dXk9w8//DB89rOfBQCAb3/722CaJtxyyy2Qy+Xg2muvhe9///unpbOCIAiCIJz9TOvlo9R/m+8QCATggQcegAceeOA9d0oQBEEQhHMXye0iCIIgCEJZOeuy2nI7lderbXVRlgm1WMmMxNg8qWjbK6/oIGgvvfQH0jarjko5P/Khq92yn0kMX9+qM5he85GrSdtq5Pfy+o5dpI37JuzYrqVmrS00LPrlV17lllNZahuMJ6g90ELSOB/rqw/JPHky0VSaSuGCIS3RctjYJVLaB6Sigt4Dy0NtqVPYPHv775jPB69jXw2ulsL+ITxsfTJF/VVw3qH9+2meojgKET42Rm3Sl1xyCalXR3X490Msy+SVV2oZ97ExajtdPFdL4Zww9bN5YS+dExW9+l46zBfBQT5EOSbxdpgfBSB/kUCIynL/9Nrr3fKBfftJ2wtbaIqE8YQOCJhOUb8ofL/ezd+rriaq/86kz7cfSZgnyEMdLl/Vk4vv0mKFKPdTKLIQ4fgvlcGOg0KvK/a/G14LTBbSnmenLSB/q6oQlUNe0vkxt8xVgk2NVHYaRBJr5s4EXhxenac14H4d6Lp4Jt8c8l/JsczGXFIcZLJPTAH5q6TT1P/BduhxO9r1dTawVAZp4vNA58SevXTOhnt0CHE+f37761/rYzLpfITpVzPIZyeTo89XAj1vswJUzltAcySTp88z1ynXhPXfVgRp6HUse/ca3AeGHRZJZrMs1EAirsf9ZA8Nr+5leux0Wt+v7qPdpM1TSSXO7wXZ+RAEQRAEoazIy4cgCIIgCGVFXj4EQRAEQSgrZ6HPB7X9V4W0rb2tjdpDC3mapA6n5/7db58hbT/84SNu+ZabP0na2pppuPfEuLb/P/Pb35K2T91ys1u+7XOfo+dHvgi5DPXN+NNP3ETq+/cfcMvc3+CC+QvccmUF1XFPBNl6S6S75inA+XupQmmkq5gfh78iqk9hs/gTBgvDWyq3OOLd4nzwMM8YbNOfNYuGW+bp1N98U6em7+mhvhoXLlzklrmNeuvWraS+bNkyt3xBM7VRN3t1f5Ytn0/7g0KmVwXoNRerqW23G9nlh9j1Z1HK7zyLKcFDa2ODfypL7dAFNF9aOujzVHvgLVLPF7SdPsN8afLMN6AUjSgtAr+tPuTz4eWp3rnjAp7qzBeBxKooMp8P5hNTQA5QeFwBAArYr4T5UVjomeHpCbzswkyftulHFi4kbTYKs+9hz1ooUEXqfhQDw2B+LhYaAsXHg9Xxc2GYzJfF0n1QwP1smMNBCZ+uykp9zS2VUdJWE2W+YqjM5wT25ykwhweLhcrHaSNyObrmKhRGPlRBx9ky2WKJxiuVpscx0dqk2ByNo/gY0SBPB8BjraAUADzdBvIJ5GkyEsw/b0+XDtePfdEAAFJJ/bd9vTSOT/ts6l8UT+o0IokkXf+qqavYe0J2PgRBEARBKCvy8iEIgiAIQlk568wufNuPaMbYTpnXR/eGdm7f5Zb/n//1XdLWUN/slufMoSF7DyETCABAejzmlhcjEwgAwI033OCWq0I0xPT/+emjbnl4mIbO7uhoI/Uly3Q22iyTdnkDepuvyN4f+dariULmGqVeNXlM5QlmGHQObhJB8sg0y+pY5OlNpyi1NdnWLzfDkP6wfVm8hVxVRbepW5hseWhI34dsloZ8rqvT0tf29nbS9tZb1ASxe/dutxyLUVNTHIWjX3v7Z0lbzzEtBU6zTJoqTyd0Pj+uz8EyHdu2nhOWl2VUZffSwVvVPnpDhoa1GaiSZd1sYLLPNDId8m38LDPnlKLCp5ehQoGZa4q6zrMpe9l8NtE84BlwS2W85VMyi8Z9LEm32JPYnMTnKH4WeTR1liHYi8KmD49S8/D4sB67urpm0pbKUql21tJzy8cGxIsk1eaErLr0fhVR3WZtNMQ8HS2bhQEv8ZhCKKxTQRQNFtafSUvTST3XEwk6PniYr/qjK0nT0osWk3pdrX6G9+3bR9qefVqb3pOpBGkLWHQM8BpjsGv0Iqk/XxtzyETCzSz5JH3ejxzW3zN9Q8Ok7cRxLYvtH+ojbSmWtfqRn25yyzxrdXWVlnVXVtLvJ6+fmqxySBrMQ8qfDmTnQxAEQRCEsiIvH4IgCIIglBV5+RAEQRAEoaycdT4fDpd6oTozVcLeXTTV8P95+BG3/Ik/vY60LbtYSyXv/frfkTbF7Ld3/83/dMsL5lFfjXRS22B/9ZOfk7aH//2HbvlzX/oiaQuFeOpjbWv2KiZny+oLtfzUDs7t19hHhittFbZjGtw3gxutJ3fWKBZxWGvaxmV7UxPaTvT54HVyTGbPxnXuK8KPs3z5crfc2kbvZRLJyzJMGn3RRReR+uHDh93y8NgIaYultJ3+KAv3jiWpRRYan6v9KlG67hCT0AWKus006HHsIh0fy9afDVdRiSP2B+F+GzzUN/YbiEajpI1Lk0vhRSntLWNyXx8Ps5lb/LnACwALb078M1gId4P9D2YimaMFTMqJ+qB4CnufPq6Hhb/nD18spsPR7359C2mrqdJhti9spv5npp/6RuQc7aeULdIxzxX12JlsXHkIdexrU+DyYvTZfJ6H7qcX5qPdI1jIhygWZ740SSrVziE5q8ND5VvaN6G9ncrBTeZs04/Swj/97Muk7cVX9feDYdDraApTf4iOWdp/MBqlbZZXr92GQb9SbSTxNlkY/5N7d5H6iOeQWx5iaTO6DuowAPF4jJ6Dza3eE3pu+dn3Q0O1nlvJLL0HXuaXFK7SNzNfEJ8PQRAEQRDOcuTlQxAEQRCEsnLWmV14dsbYqN7i/v73niBtP/7R/0vqlyzX2UVnLadZSZ956kW3XB1pIm1RJE8CAPjNk8+75dcbaRbDAJLQPfnE46StgEwZFy9dRtoySFoGAJBPxNxyNk6lZgVk5qiuo9E0/ZV039NB280elv3VQHLEYpHu3XHFnAcdx2H7fE5e9yefo1u2NtumPV1ml1IRTnEERJ7dlGe2DKNMyF4vlZr5/XrcsSQXYKJZAZsdshm6hTyvRWeA3LmNRkadO+9C3TeTyg8r2f8GYZ/eQr2wYx5pi2T1dSZjNFulzaJi2gG9TexwewDaRs8X6NZvjplhQiE91wJMljudCKc4Lafi0mz0vDvMFGiztQDLSRW7LptEjGR/Z00ePbeCRaX0AYr2aXJzlj6HyaONMulvEY3XssXUhDe7Tq8/YWaOLTKdp9/Qc9bM0jHPFfHY8ftMx1Lh6JpFdu/QnMAmMoCJWX9LUd+sZe6pAo0mnGcZX9NZ/QxlmPzaQdLxQobK40eSMVL//R90lvHf/PZ3pG00rs/BbiX4melpXr02czbU0zU/m9f3ZJTJgj0efeA8W2PjY7Sv3hDKRpuk569r0Oa3UBX9rohWU8nuvIDua08/Xbf6Y7p/JwZo25xmalbF5HPTeJ6niOx8CIIgCIJQVuTlQxAEQRCEsiIvH4IgCIIglJWzzufDw+y+RZQ1EFjI6RtvoHLaVStWueVt22l47Dd27XXLczvmkrYCC2++700dpvcPrwyStoqgtuVWV9eRtsUX6Oy4Pd3HSVtNiNrMPUhCV+WnNulCVvsbDByj9r5ITQ2pW8iPweOj9msP8iHIMTnmkcPHSL23B/WXyfZSaT0+/koqAfVV0DGYOjzEM69rW7PJDbbIY4X7fHBwu8/HfC5QxuAMC0U8OEjv+3gs5pYbGhtIW22NHoODBw+RtmxG30uPRR9HkylJfShEuNdHPxtAfjgef5Seo4r23UFhlPPMnp5B/VFMXm0zPwEfytzq8dA54fNNfWkponDmPEkqkc96mK8Ru+0GmZfMNwHPgwlZUpk9G/uOsOmDfZ8MFrbewP4qfL4yX5aqoPY1unDeUnocVHaYnNgEusZ50PhUslDaXqTVtpmfVoGNjw9dc56nK8BdeJfY9KUSZ/sqtO+cadIQ4UUm83TQgXn24BzK8Jocpz4Wyqa+WP39OnNrXz89ZwFPLTZ2BnsWK8LazyPP/mc/MaT9DkeZDHZOq/ajSGToPBtOU9+wtrD2oeo+coS0vTWox702RPvWWEvrFkq10NNLfWtwqg6etiPDfLqwzN3ylIib/x6RnQ9BEARBEMqKvHwIgiAIglBW5OVDEARBEISyctb5fChmsI1EtR3xk5/6NGkrZGmYawtd7ryF1M56+dWXu+VwuJK0VUeoH0NsRKdM7+8dIG0+n7avN89uJW3hiI63UFFJ/S/sAgutDdrfwOOl9rYoCntbYJp8rsdOoLDFDrNRV6NQuwUWDjqVpLbU+Lj2Lckybb0/qK8rXE018NxWONU4HzweB4/rYePYEMzubFmTh1e3WVjpUvFCDGL7Z3EjbOr/gH0l+FWOozDtuSI9fyan7aw+H40zYjKfCw9q554sPuQX1NxI49QMFGka9hEUQ4Zfvwf5vSg2VhUWjTmB4ePKw26XgvudkOOg4zomtVHz2C8WipNSyLPzKz0PDB5zg8e8QBOKjw9OUc5DZ3gUDnHPTs/CtCvky8F9aSakOigBHmceMh0/0oo50yg2fw10Mdx/B/e9yP7O4WkXSroG6L/NJOmcdJjPRyWKV1Rk61Yhoz/LH98U86vIofHxsZgteNwNFuulqp76ziVtfdyu4zSOzsi4bgtYfOxQv9k1DjP/kLpZeh2dP4+Gjf/Dwe1uOZOmE+/SiztJvW9Afz9FK+l15ZEfW08yQdocNkeKRT0+frY2nQ5k50MQBEEQhLIyrZePBx98EJYtWwbhcBjC4TB0dnbC736no8Zls1lYt24d1NbWQigUgltuuQUGBgZKHFEQBEEQhPONaZldWlpa4P7774f58+eDUgp+/OMfw4033gg7d+6Eiy66CO666y74zW9+A5s2bYJIJALr16+Hm2++GV555ZXT1mHbZHJEvzZzRGqpxNEu0K2iQlZve1lBul24rFZL3yyLydJy1CQSCetw2UtYdlPLq+WrRZuaJ7I5VGf7hXmHSRUrtTnJYaYLrwfJQ9lxzCSVmnlD+rNFFi7bRFJbo0jbWttbSH3xRToMOA+vPjqmt1AtPzVZDYzQMZgq7xZOHZtTuIwQm2FKZcPllDLBVFbS66qtpeYlvP2dYxK2JNpiPnaMSphHRrRpcOHChaQtFKBmjhzaJs6xLfZx9Fw4tbNIW98YDaN89ITOrMtDpmPzyezZs0lbHbtmvC3Lx3k6ZpcsMrsoJqUv2DqU9PAozQg8OjpM6m2tF7jlmupm0ub16PtnKW4b4Pd9crMLnlv8Gqn5hptO2BwFbDbkJpnJx45Lx/H9KmV2sXlfi5Obmop8+90uoDI3r9F6KUVmLqbv19FDB0hbKkXNMM3Veu4lU3SOplBqg1/85y9J2+AInRMDY9p8HK6laTKqx/TcyrB0CbNqo6ReVaVNIvEU/Sy29AQqWJoBZI61WYZZYM9MCoVm75hL198Vc/UzHY7STNQ3XHctqR86dNQtW+Z20uYJ6udghEmPA2y9wZm8p24InDrTevn4+Mc/Tur33XcfPPjgg/Dqq69CS0sLPPTQQ/Doo4/CRz/6UQAAePjhh2HRokXw6quvwuWXX36qQwqCIAiCcJ7xnn0+bNuGxx57DFKpFHR2dsKOHTugUCjAmjVr3M8sXLgQ2traYMuWLZMeJ5fLQTweJz+CIAiCIJy7TPvlY8+ePRAKhcDv98Mdd9wBjz/+OCxevBj6+/vB5/OR7J4AAA0NDSTKHGfjxo0QiUTcn9bW1kk/KwiCIAjC2c+0pbYXXngh7Nq1C8bHx+GXv/wlrF27Fl588cV3/8NJuOeee2DDhg1uPR6Pl3wBcYD7LSD7bJDKikw/TS/vq9D2ST+LzewxsQ8BlWtNkM3hKMosHLSBPuxnkj4/CnPNJWoRi0q7HGSHzheoDwGR5jG7YaiOpk/HqbyLTOaZRfb+3CgNF378xFFS91raf4ZLbW1b92FOx3zSZrIBsqZoPUwkqAzM72eh4ZEUl4dFx+Ztbtsu5QNSyueD29qxDfjtc+qT9vVTJ+ueHu2rMD5O02EfQWGUuT8I9/nIIqle1mbhqJHfS4BLSZk8MjYec8u5HL2XjY06HHRTE5XscjktHksuacZjmWfpyTkF5DdgGNQ3IZHSUvGdu3eRNr5L6kEy93CU+n+ZOFw386kw2L3F95LfdxzKn0u8bTX5OUpJbR3F/S8mP3+pulMipPtEXw1n0rpt8/UG+3xMPu8AADwlFJndB3RKi4P7aXoLj5d+FVVWaN+ERJz6WOTzen0eHqXhFDJ5NpaGPm4kTH0uaqp1CIU8O/8s9nz70Vz3MOkvlsT7vUzaiv0mqljI9iBNe2CgW9QYpJ+945Yb3HKUSekXLFhA6vPadXqQBRd0kLYxFI7+lS2vkTYPf4bRd9AHYZGY9suHz+eDefPmAQDAypUr4bXXXoPvfve78KlPfQry+TzEYjGy+zEwMEAWNI7f75/wxSIIgiAIwrnL+47z4TgO5HI5WLlyJXi9Xti8ebPb1tXVBcePH4fOzs4SRxAEQRAE4XxiWjsf99xzD1x//fXQ1tYGiUQCHn30UXjhhRfg6aefhkgkAl/4whdgw4YNUFNTA+FwGL785S9DZ2enKF0EQRAEQXCZ1svH4OAg3H777dDX1weRSASWLVsGTz/9NHzsYx8DAIBvf/vbYJom3HLLLZDL5eDaa6+F73//+6e3x0Vql0oltQ0yHudadrqxYyJbuMn1+za2s1LDJfcFMEoFCTdOWXz7uLgv/Pz8s8gG6zD/FNvRt21iaHE6Ph4SD4N+NpfX9slkntofIUBt5gaKXxKtpjEvHBSjxKqgvivZAZrSmYd5ngysMQeg/ikAAOGw1rpzPw6Px4vKdIrz45SKVYHhc4B/FtveU2na971733TLSRZWGv8dD8g3xGcQdj5iYZxx3Jgk65uXOS3hMO6BALWDY3+rIGvjfgJ8bDFkHr6Lz0cRHZc/W16ftr0vXHgJaauopHO2prpOVwz6DBfR820azA9ogh9FKZ8PFF6dPXvEF4zH7mA+Hzg2+wRfjZJtk/t88DZjks+dqo590Ph9xj5mE/xB7KnHc6lEz2xFlMaMAZM/p9oXic+exgYd8+LWT95C2roOdpH6m/t0/eQgjQGSzqKU9gW6Lgz30RgYcZS+IF/kz5Nus9hziV1QMjxdgp/6h3j9egwSzDfMcbT/V47HbGFxqKpq9NjOaaLrcRD11W/RZ6QiSOs4fhNMI+T/VJnWy8dDDz1Usj0QCMADDzwADzzwwPvqlCAIgiAI5y6S20UQBEEQhLJy1mW19bOtqq1btrnl3bv2kTaluEYWyeR4uGMTbyuVMphM3LLElJJrTgdyhhJbv3xb1jQmNwcofh1oG9Aw2Zagj5pvSBdYBlwDTSMeVTudpNuH4ag22WRp1G9CXR3dlh0YoFLg0VGdubG6moZNDgR0/3imWB4mvYBkzAUmacZwM0up8O8N9fRvk+16e5efg5uBSp0DmzK8zORhYemxn14zl9D5UXswSOW8WKlmsXN4mYwQ96dU+Pt3I5fXW+wGS4tqmNr009BwAW1jjxpVVXNZMDa7sL7y/8FKSG1ppmP2Z+g43HTBJcQ43LozIbw6kuE6k5uEePsECTEqT8g6bHPTCg7TzjLD2npbv8iyaBeYlD1EFaqEF17WwSa7T1Czhumh89DGZiB2HA+ah8PDdBFJskyxFy9Z5JYXs6+7/mH92b6jVOaeYqaMUST951mRPShcP78HloWUnDz0AsuyG0CZzuPMPNs7eNgtV9fWkTaLf81Z+joNm64vmQxKzeGl60T7HBrioufkGKqdfrOL7HwIgiAIglBW5OVDEARBEISyIi8fgiAIgiCUFUOVcmCYAeLxOEQiEfja174mkU8FQRAE4Swhl8vB/fffD+Pj4yQcwqmQnQ9BEARBEMqKvHwIgiAIglBW5OVDEARBEISyIi8fgiAIgiCUFXn5EARBEAShrJxxEU7fEd/kcrl3+aQgCIIgCGcK73xvT0VEe8ZJbU+cOEEyawqCIAiCcPbQ09MDLS0tJT9zxr18OI4Dvb29oJSCtrY26OnpeVe98PlIPB6H1tZWGZ9JkPEpjYxPaWR8SiPjMznn89gopSCRSEBzc/OE3FScM87sYpomtLS0QDweBwCAcDh83t3A6SDjUxoZn9LI+JRGxqc0Mj6Tc76OTSQSmdLnxOFUEARBEISyIi8fgiAIgiCUlTP25cPv98Pf/d3fSX6XSZDxKY2MT2lkfEoj41MaGZ/JkbGZGmecw6kgCIIgCOc2Z+zOhyAIgiAI5yby8iEIgiAIQlmRlw9BEARBEMqKvHwIgiAIglBW5OVDEARBEISycsa+fDzwwAPQ3t4OgUAAVq9eDdu2bZvpLpWdjRs3wqWXXgpVVVVQX18PN910E3R1dZHPZLNZWLduHdTW1kIoFIJbbrkFBgYGZqjHM8v9998PhmHAnXfe6f7ufB+fkydPwmc+8xmora2FYDAIS5cuhe3bt7vtSim49957oampCYLBIKxZswYOHjw4gz0uH7Ztwze/+U3o6OiAYDAIc+fOhX/4h38gSbHOp/F56aWX4OMf/zg0NzeDYRjwxBNPkPapjMXo6CjcdtttEA6HIRqNwhe+8AVIJpNlvIoPjlLjUygU4O6774alS5dCZWUlNDc3w+233w69vb3kGOfy+EwbdQby2GOPKZ/Pp370ox+pN998U/3lX/6likajamBgYKa7VlauvfZa9fDDD6u9e/eqXbt2qT/5kz9RbW1tKplMup+54447VGtrq9q8ebPavn27uvzyy9UVV1wxg72eGbZt26ba29vVsmXL1Fe+8hX39+fz+IyOjqo5c+aoz372s2rr1q3qyJEj6umnn1aHDh1yP3P//ferSCSinnjiCfXGG2+oT3ziE6qjo0NlMpkZ7Hl5uO+++1Rtba168sknVXd3t9q0aZMKhULqu9/9rvuZ82l8fvvb36pvfOMb6le/+pUCAPX444+T9qmMxXXXXaeWL1+uXn31VfX73/9ezZs3T916661lvpIPhlLjE4vF1Jo1a9TPf/5ztX//frVlyxZ12WWXqZUrV5JjnMvjM13OyJePyy67TK1bt86t27atmpub1caNG2ewVzPP4OCgAgD14osvKqXenvBer1dt2rTJ/cxbb72lAEBt2bJlprpZdhKJhJo/f7565pln1Ic//GH35eN8H5+7775bXXXVVZO2O46jGhsb1b/8y7+4v4vFYsrv96uf/exn5ejijHLDDTeoz3/+8+R3N998s7rtttuUUuf3+PAv16mMxb59+xQAqNdee839zO9+9ztlGIY6efJk2fpeDk71csbZtm2bAgB17NgxpdT5NT5T4Ywzu+TzedixYwesWbPG/Z1pmrBmzRrYsmXLDPZs5hkfHwcAgJqaGgAA2LFjBxQKBTJWCxcuhLa2tvNqrNatWwc33HADGQcAGZ//+q//glWrVsGf//mfQ319PaxYsQJ++MMfuu3d3d3Q399PxicSicDq1avPi/G54oorYPPmzXDgwAEAAHjjjTfg5Zdfhuuvvx4AZHwwUxmLLVu2QDQahVWrVrmfWbNmDZimCVu3bi17n2ea8fFxMAwDotEoAMj4cM64rLbDw8Ng2zY0NDSQ3zc0NMD+/ftnqFczj+M4cOedd8KVV14JS5YsAQCA/v5+8Pl87uR+h4aGBujv75+BXpafxx57DF5//XV47bXXJrSd7+Nz5MgRePDBB2HDhg3w9a9/HV577TX467/+a/D5fLB27Vp3DE71rJ0P4/O1r30N4vE4LFy4ECzLAtu24b777oPbbrsNAOC8Hx/MVMaiv78f6uvrSbvH44Gamprzbryy2SzcfffdcOutt7qZbWV8KGfcy4dwatatWwd79+6Fl19+eaa7csbQ09MDX/nKV+CZZ56BQCAw090543AcB1atWgX/9E//BAAAK1asgL1798IPfvADWLt27Qz3bub5xS9+AT/96U/h0UcfhYsuugh27doFd955JzQ3N8v4CO+ZQqEAn/zkJ0EpBQ8++OBMd+eM5Ywzu9TV1YFlWRMUCQMDA9DY2DhDvZpZ1q9fD08++SQ8//zz0NLS4v6+sbER8vk8xGIx8vnzZax27NgBg4ODcMkll4DH4wGPxwMvvvgifO973wOPxwMNDQ3n9fg0NTXB4sWLye8WLVoEx48fBwBwx+B8fdb+5m/+Br72ta/Bpz/9aVi6dCn8xV/8Bdx1112wceNGAJDxwUxlLBobG2FwcJC0F4tFGB0dPW/G650Xj2PHjsEzzzzj7noAyPhwzriXD5/PBytXroTNmze7v3McBzZv3gydnZ0z2LPyo5SC9evXw+OPPw7PPfccdHR0kPaVK1eC1+slY9XV1QXHjx8/L8bqmmuugT179sCuXbvcn1WrVsFtt93mls/n8bnyyisnSLMPHDgAc+bMAQCAjo4OaGxsJOMTj8dh69at58X4pNNpME26BFqWBY7jAICMD2YqY9HZ2QmxWAx27Njhfua5554Dx3Fg9erVZe9zuXnnxePgwYPw7LPPQm1tLWk/38dnAjPt8XoqHnvsMeX3+9Ujjzyi9u3bp774xS+qaDSq+vv7Z7prZeWv/uqvVCQSUS+88ILq6+tzf9LptPuZO+64Q7W1tannnntObd++XXV2dqrOzs4Z7PXMgtUuSp3f47Nt2zbl8XjUfffdpw4ePKh++tOfqoqKCvUf//Ef7mfuv/9+FY1G1a9//Wu1e/dudeONN56zUlLO2rVr1ezZs12p7a9+9StVV1envvrVr7qfOZ/GJ5FIqJ07d6qdO3cqAFD/+q//qnbu3OmqNaYyFtddd51asWKF2rp1q3r55ZfV/Pnzzxkpaanxyefz6hOf+IRqaWlRu3btIut1Lpdzj3Euj890OSNfPpRS6t/+7d9UW1ub8vl86rLLLlOvvvrqTHep7ADAKX8efvhh9zOZTEZ96UtfUtXV1aqiokL92Z/9merr65u5Ts8w/OXjfB+f//7v/1ZLlixRfr9fLVy4UP37v/87aXccR33zm99UDQ0Nyu/3q2uuuUZ1dXXNUG/LSzweV1/5yldUW1ubCgQC6oILLlDf+MY3yJfF+TQ+zz///CnXm7Vr1yqlpjYWIyMj6tZbb1WhUEiFw2H1uc99TiUSiRm4mtNPqfHp7u6edL1+/vnn3WOcy+MzXQylUDg/QRAEQRCED5gzzudDEARBEIRzG3n5EARBEAShrMjLhyAIgiAIZUVePgRBEARBKCvy8iEIgiAIQlmRlw9BEARBEMqKvHwIgiAIglBW5OVDEARBEISyIi8fgiAIgiCUFXn5EARBEAShrMjLhyAIgiAIZeX/A5Tka0IehWtAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.3241\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.2896\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.3169\n",
            "Epoch [1/5], Step [8000/12500], Loss: 2.2714\n",
            "Epoch [1/5], Step [10000/12500], Loss: 2.0483\n",
            "Epoch [1/5], Step [12000/12500], Loss: 1.9428\n",
            "Epoch [2/5], Step [2000/12500], Loss: 2.1577\n",
            "Epoch [2/5], Step [4000/12500], Loss: 1.5992\n",
            "Epoch [2/5], Step [6000/12500], Loss: 1.9605\n",
            "Epoch [2/5], Step [8000/12500], Loss: 2.4640\n",
            "Epoch [2/5], Step [10000/12500], Loss: 2.1229\n",
            "Epoch [2/5], Step [12000/12500], Loss: 1.0702\n",
            "Epoch [3/5], Step [2000/12500], Loss: 1.4054\n",
            "Epoch [3/5], Step [4000/12500], Loss: 1.6083\n",
            "Epoch [3/5], Step [6000/12500], Loss: 1.6593\n",
            "Epoch [3/5], Step [8000/12500], Loss: 2.2008\n",
            "Epoch [3/5], Step [10000/12500], Loss: 1.8215\n",
            "Epoch [3/5], Step [12000/12500], Loss: 1.4026\n",
            "Epoch [4/5], Step [2000/12500], Loss: 1.1455\n",
            "Epoch [4/5], Step [4000/12500], Loss: 1.8499\n",
            "Epoch [4/5], Step [6000/12500], Loss: 1.7949\n",
            "Epoch [4/5], Step [8000/12500], Loss: 1.4852\n",
            "Epoch [4/5], Step [10000/12500], Loss: 1.4252\n",
            "Epoch [4/5], Step [12000/12500], Loss: 1.4583\n",
            "Epoch [5/5], Step [2000/12500], Loss: 1.0879\n",
            "Epoch [5/5], Step [4000/12500], Loss: 0.8598\n",
            "Epoch [5/5], Step [6000/12500], Loss: 0.6971\n",
            "Epoch [5/5], Step [8000/12500], Loss: 1.5420\n",
            "Epoch [5/5], Step [10000/12500], Loss: 0.7414\n",
            "Epoch [5/5], Step [12000/12500], Loss: 2.0958\n",
            "Finished Training\n",
            "Accuracy of the network: 48.45 %\n",
            "Accuracy of plane: 53.6 %\n",
            "Accuracy of car: 65.0 %\n",
            "Accuracy of bird: 22.0 %\n",
            "Accuracy of cat: 20.1 %\n",
            "Accuracy of deer: 21.9 %\n",
            "Accuracy of dog: 55.0 %\n",
            "Accuracy of frog: 73.3 %\n",
            "Accuracy of horse: 50.6 %\n",
            "Accuracy of ship: 58.8 %\n",
            "Accuracy of truck: 64.2 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/hymenoptera_data.zip'\n",
        "extract_path = '/content/data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(class_names)\n",
        "\n",
        "\n",
        "def imshow(inp, title):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "#### Finetuning the convnet ####\n",
        "# Load a pretrained model and reset final fully connected layer.\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "# Learning rate scheduling should be applied after optimizer’s update\n",
        "# e.g., you should write your code this way:\n",
        "# for epoch in range(100):\n",
        "#     train(...)\n",
        "#     validate(...)\n",
        "#     scheduler.step()\n",
        "\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "# Here, we need to freeze all the network except the final layer.\n",
        "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "jMJZs-Zo0vZj",
        "outputId": "eedfd8ba-693b-45f5-b888-f835b1195f9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2510e65572d3>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mextract_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hymenoptera_data.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "###################################################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "            ############## TENSORBOARD ########################\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "            ###################################################\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "    # 10000, 10, and 10000, 1\n",
        "    # stack concatenates tensors along a new dimension\n",
        "    # cat concatenates tensors in the given dimension\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    ############## TENSORBOARD ########################\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()\n",
        "    ###################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "9R4RF_E40xnr",
        "outputId": "5757fdba-b0fd-47bb-9407-eada713ca369"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/938], Loss: 0.2601\n",
            "Epoch [1/1], Step [200/938], Loss: 0.1731\n",
            "Epoch [1/1], Step [300/938], Loss: 0.3318\n",
            "Epoch [1/1], Step [400/938], Loss: 0.2751\n",
            "Epoch [1/1], Step [500/938], Loss: 0.1477\n",
            "Epoch [1/1], Step [600/938], Loss: 0.1886\n",
            "Epoch [1/1], Step [700/938], Loss: 0.2906\n",
            "Epoch [1/1], Step [800/938], Loss: 0.1488\n",
            "Epoch [1/1], Step [900/938], Loss: 0.0655\n",
            "Accuracy of the network on the 10000 test images: 96.12 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "# train your model...\n",
        "\n",
        "####################save all ######################################\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# save and load entire model\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for param in loaded_model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "############save only state dict #########################\n",
        "\n",
        "# save only state dict\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "print(model.state_dict())\n",
        "loaded_model = Model(n_input_features=6)\n",
        "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n",
        "###########load checkpoint#####################\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "checkpoint = {\n",
        "\"epoch\": 90,\n",
        "\"model_state\": model.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "print(optimizer.state_dict())\n",
        "FILE = \"checkpoint.pth\"\n",
        "torch.save(checkpoint, FILE)\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()\n",
        "\n",
        "print(optimizer.state_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLxhqfRk0zij",
        "outputId": "2a4e7275-29c5-491b-d859-7c76e0c69b08"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1999, -0.2574,  0.3710,  0.0555, -0.2373, -0.0532]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1349], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.1999, -0.2574,  0.3710,  0.0555, -0.2373, -0.0532]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1349], requires_grad=True)\n",
            "OrderedDict([('linear.weight', tensor([[-0.1999, -0.2574,  0.3710,  0.0555, -0.2373, -0.0532]])), ('linear.bias', tensor([-0.1349]))])\n",
            "OrderedDict([('linear.weight', tensor([[-0.1999, -0.2574,  0.3710,  0.0555, -0.2373, -0.0532]])), ('linear.bias', tensor([-0.1349]))])\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        }
      ]
    }
  ]
}